#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YOLO11å©´å„¿å…³é”®ç‚¹æ£€æµ‹è®­ç»ƒå™¨
å°è£…ä¸ºå¯é‡ç”¨çš„è®­ç»ƒå™¨ç±»
"""

import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import random
from tqdm import tqdm
import yaml
import json
import logging

# TensorBoardæ”¯æŒ
try:
    from torch.utils.tensorboard.writer import SummaryWriter
    TENSORBOARD_AVAILABLE = True
except ImportError:
    TENSORBOARD_AVAILABLE = False
    logging.getLogger(__name__).warning("TensorBoard ä¸å¯ç”¨ï¼Œå°†ä¸è®°å½•è®­ç»ƒæ—¥å¿—")
    class DummySummaryWriter:
        def __init__(self, *args, **kwargs): pass
        def add_scalar(self, *args, **kwargs): pass
        def add_image(self, *args, **kwargs): pass
        def close(self): pass
    SummaryWriter = DummySummaryWriter

logger = logging.getLogger(__name__)

from loss import PoseLoss
from yolo_dataset import build_datasets_and_loaders
from validater import YOLOValidater
from metrics import MetricsTracker  # ç²¾ç®€ååªéœ€ç»¼åˆè·Ÿè¸ªå™¨
from utils import AverageMeter
from config_utils import load_config


class YOLOTrainer:
    """YOLOå…³é”®ç‚¹æ£€æµ‹è®­ç»ƒå™¨"""
    
    def __init__(self, model, config=None):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        
        Args:
            model: YOLO11KeypointModelå®ä¾‹
            config: è®­ç»ƒé…ç½®å­—å…¸
        """
        self.model = model
        self.device = next(model.parameters()).device
        self.config = config if config is not None else load_config()
        # è®­ç»ƒçŠ¶æ€
        self.start_epoch = 0
        self.best_loss = float('inf')  # ä»è¿½è¸ªæœ€ä¼˜éªŒè¯æŸå¤± (å…¼å®¹æ—§é€»è¾‘)
        # ---- é€šç”¨æ—©åœæŒ‡æ ‡é…ç½® ----
        self.best_metric_name = self.config.get('early_stop_metric', 'val_loss')
        self.best_metric_mode = str(self.config.get('early_stop_mode', 'min')).lower()
        if self.best_metric_mode not in ('min', 'max'):
            self.best_metric_mode = 'min'
        try:
            self.best_metric_delta = float(self.config.get('early_stop_delta', 0.0))
        except Exception:
            self.best_metric_delta = 0.0
        self.early_stop_enabled = bool(self.config.get('early_stop', True))
        self.best_metric_value = None  # é¦–æ¬¡ä¸€å®šè§†ä¸ºæ”¹è¿›
        self.best_metric_epoch = None
        self.train_losses = []
        self.val_losses = []
        self.patience_counter = 0
        self.global_iter = 0
        self.base_lrs = None

        # éšæœºç§å­
        self._set_seed(self.config.get('seed'))

        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_optimizer()
        self._setup_scheduler()
        self._setup_criterion()
        self._setup_directories()
        self._setup_tensorboard()
        self._setup_validater()
        self._setup_metrics_tracker()  # æ·»åŠ æŒ‡æ ‡è·Ÿè¸ªå™¨åˆå§‹åŒ–
        # å°†é…ç½®æŒ‚åˆ°æ¨¡å‹ä¸Šï¼Œä¾¿äºéªŒè¯å™¨è¯»å– (å¦‚ kpt_vis_threshold)
        try:
            setattr(self.model, 'config', self.config)
        except Exception:
            pass
        # å°†é…ç½®åŒæ­¥åˆ°æ¨¡å‹çš„ headï¼ˆå¦‚ Top-K èåˆç­‰æ¨ç†ç­–ç•¥ï¼‰
        try:
            if hasattr(self.model, 'apply_config'):
                self.model.apply_config(self.config)
            else:
                # å›é€€ï¼šç›´æ¥å†™åˆ° head å±æ€§ä¸Šï¼ˆè‹¥å­˜åœ¨ï¼‰
                if hasattr(self.model, 'head') and self.model.head is not None:
                    hk = getattr(self.model.head, 'topk', None)
                    setattr(self.model.head, 'topk_fuse', bool(self.config.get('topk_fuse', getattr(self.model.head, 'topk_fuse', False))))
                    setattr(self.model.head, 'topk', int(self.config.get('topk', hk if hk is not None else 5)))
                    setattr(self.model.head, 'fuse_temp', float(self.config.get('fuse_temp', getattr(self.model.head, 'fuse_temp', 0.5))))
        except Exception:
            pass
        # å¯è§†åŒ–ç›¸å…³é…ç½®
        self.visual_interval = self.config.get('visual_interval', 5)
        self.max_vis_images = self.config.get('visual_max_images', 2)

        # AMP æ”¯æŒ
        self.amp_enabled = bool(self.config.get('amp') and torch.cuda.is_available())
        self.scaler = torch.cuda.amp.GradScaler(enabled=self.amp_enabled)
        # CSV è·¯å¾„
        self.csv_path = os.path.join(self.config['save_dir'], 'results.csv')
        # JSON è·¯å¾„: ç”¨äºä¿å­˜æ¯ä¸ª epoch çš„è®­ç»ƒ/éªŒè¯æŸå¤±
        self.epoch_losses_path = os.path.join(self.config['save_dir'], 'epoch_losses.json')
    
    def _setup_optimizer(self):
        """è®¾ç½®ä¼˜åŒ–å™¨ï¼ˆå‚æ•°ç»„åŒºåˆ†æ˜¯å¦åº”ç”¨ weight_decayï¼‰"""
        decay, no_decay = [], []
        for n, p in self.model.named_parameters():
            if not p.requires_grad:
                continue
            if p.dim() == 1 or n.endswith('.bias'):
                no_decay.append(p)
            else:
                decay.append(p)
        param_groups = [
            {'params': decay, 'weight_decay': self.config['weight_decay']},
            {'params': no_decay, 'weight_decay': 0.0}
        ]
        # ä¼˜å…ˆå°è¯• AdamW, ä¸å¯ç”¨åˆ™å›é€€ SGD
        opt = None
        AdamWCls = getattr(optim, 'AdamW', None)
        if AdamWCls is not None:
            try:
                opt = AdamWCls(param_groups, lr=self.config['lr'])
            except Exception:
                opt = None
        if opt is None:
            SGDCls = getattr(optim, 'SGD', None)
            if SGDCls is None:
                raise RuntimeError('æœªæ‰¾åˆ°å¯ç”¨ä¼˜åŒ–å™¨ AdamW æˆ– SGD')
            opt = SGDCls(param_groups, lr=self.config['lr'], momentum=0.9)
        self.optimizer = opt
        self.base_lrs = [g.get('lr', self.config['lr']) for g in self.optimizer.param_groups]
    
    def _setup_scheduler(self):
        """è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨"""
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=self.config['epochs'],
            eta_min=self.config['lr'] * 0.01
        )
    
    def _setup_criterion(self):
        """è®¾ç½®æŸå¤±å‡½æ•° & åŠ¨æ€æŸå¤±é¡¹åç§°"""
        self.criterion = PoseLoss(self.model)
        # ç°åœ¨ PoseLoss è¿”å›äº”ä¸ªåˆ†é‡ï¼šbbox, kpt_loc, kpt_vis, cls, dfl
        self.loss_names = ['bbox', 'kpt_loc', 'kpt_vis', 'cls', 'dfl']
    
    def _setup_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        os.makedirs(self.config['save_dir'], exist_ok=True)
        os.makedirs(self.config['log_dir'], exist_ok=True)
    
    def _setup_tensorboard(self):
        """è®¾ç½®TensorBoard"""
        if TENSORBOARD_AVAILABLE:
            self.writer = SummaryWriter(self.config['log_dir'])
        else:
            self.writer = SummaryWriter()
    
    def _setup_validater(self):
        """è®¾ç½®éªŒè¯å™¨å¹¶é…ç½®å¯é€‰å¯è§†åŒ–"""
        vis_enable = bool(self.config.get('val_visualize', True))
        vis_interval = int(self.config.get('val_visual_interval', 1))
        vis_max = int(self.config.get('val_visual_max_images', 2))
        if TENSORBOARD_AVAILABLE and hasattr(self.writer, 'add_scalar'):
            self.validater = YOLOValidater(
                self.model,
                self.criterion,
                self.device,
                writer=self.writer,  # type: ignore[arg-type]
                enable_tb=True,
                save_dir=os.path.join(self.config['save_dir'], 'val_vis'),
                visualize=vis_enable,
                vis_interval=vis_interval,
                vis_max_images=vis_max
            )
        else:
            self.validater = YOLOValidater(
                self.model,
                self.criterion,
                self.device,
                enable_tb=False,
                save_dir=os.path.join(self.config['save_dir'], 'val_vis'),
                visualize=vis_enable,
                vis_interval=vis_interval,
                vis_max_images=vis_max
            )
    
    def _setup_metrics_tracker(self):
        """è®¾ç½®æŒ‡æ ‡è·Ÿè¸ªå™¨"""
        vis_thr = float(self.config.get('kpt_vis_threshold', 0.5))
        self.metrics_tracker = MetricsTracker(
            num_classes=self.model.nc,
            num_keypoints=self.model.nk,
            vis_threshold=vis_thr
        )

    def preprocess_batch(self, batch):
        """é¢„å¤„ç† dataloader è¿”å›çš„ batchï¼ˆæ¥è‡ª `pad_collate`ï¼‰ã€‚

        - å°†æ‰€æœ‰ tensor ç§»åŠ¨åˆ°è®¾å¤‡å¹¶è§„èŒƒ dtype
        - ä¿ç•™é tensor é¡¹ï¼ˆå¦‚ img_pathsï¼‰åŸæ ·è¿”å›
        è¿”å›: images, batch_on_device
        """
        batch_on_device = {}
        for k, v in batch.items():
            if isinstance(v, torch.Tensor):
                try:
                    batch_on_device[k] = v.to(self.device)
                except Exception:
                    batch_on_device[k] = v
            else:
                batch_on_device[k] = v

        # è§„èŒƒå¸¸ç”¨ key çš„ dtype
        if 'images' in batch_on_device and isinstance(batch_on_device['images'], torch.Tensor):
            images = batch_on_device['images'].float()
            batch_on_device['images'] = images
        else:
            images = None

        if 'cls' in batch_on_device and isinstance(batch_on_device['cls'], torch.Tensor):
            batch_on_device['cls'] = batch_on_device['cls'].float()
        if 'bboxes' in batch_on_device and isinstance(batch_on_device['bboxes'], torch.Tensor):
            batch_on_device['bboxes'] = batch_on_device['bboxes'].float()
        if 'batch_idx' in batch_on_device and isinstance(batch_on_device['batch_idx'], torch.Tensor):
            batch_on_device['batch_idx'] = batch_on_device['batch_idx'].long()
        if 'keypoints' in batch_on_device and isinstance(batch_on_device['keypoints'], torch.Tensor):
            batch_on_device['keypoints'] = batch_on_device['keypoints'].float()

        return images, batch_on_device
    
    def setup_data_loaders(self):
        """è®¾ç½®æ•°æ®é›†ä¸åŠ è½½å™¨"""
        self.train_loader, self.val_loader, train_dataset, val_dataset = build_datasets_and_loaders()
            
        if len(train_dataset) == 0:
            raise ValueError(f"è®­ç»ƒæ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„: {self.config['data_root']}")
        
        if len(val_dataset) == 0:
            raise ValueError(f"éªŒè¯æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„: {self.config['data_root']}")
        # æŒ‚è½½åˆ°å®ä¾‹ï¼Œä¾¿äºå¤–éƒ¨è®¿é—®å¹¶åœ¨æ­¤å¤„æ‰“å°ä¿¡æ¯ï¼ˆé¿å…æ¨¡å—å¯¼å…¥æ—¶æ‰§è¡Œï¼‰
        self.train_dataset = train_dataset
        self.val_dataset = val_dataset

        logger.info("è®­ç»ƒé›†: %d æ ·æœ¬", len(train_dataset))
        logger.info("éªŒè¯é›†: %d æ ·æœ¬", len(val_dataset))
            

    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        losses = AverageMeter()
        bbox_losses = AverageMeter()
        kpt_loc_losses = AverageMeter()
        kpt_vis_losses = AverageMeter()
        cls_losses = AverageMeter()
        dfl_losses = AverageMeter()
        
        # é‡ç½®epochæŒ‡æ ‡
        self.metrics_tracker.start_epoch()
        
        # åˆ›å»ºè¿›åº¦æ¡
        # Use dynamic_ncols so the progress bar adapts to terminal width and avoids truncation
        pbar = tqdm(
            self.train_loader,
            desc=f'Train Epoch {epoch+1}/{self.config["epochs"]}',
            dynamic_ncols=True,
            leave=False  # è®­ç»ƒå®Œæˆåæ¸…é™¤è¿›åº¦æ¡
        )
        
        warmup_epochs = max(0, int(self.config.get('warmup_epochs', 0)))
        # çº¿æ€§ warmup: ç›´æ¥åœ¨ optimizer.param_groups ä¸Šä¿®æ”¹ lr, ä¸åç»­ CosineAnnealingLR.step() å åŠ ã€‚
        # å½“å‰å®ç°: warmup æœŸé—´æ‰‹åŠ¨çº¿æ€§æå‡åˆ° base_lr, ä¹‹å scheduler.cosine ä¼šä»å½“å‰ç»„ lr ç»§ç»­è¡°å‡ã€‚
        # è‹¥éœ€ç²¾ç¡®çš„ "warmup + cosine" ç»„åˆï¼Œå¯æ”¹ä¸ºä½¿ç”¨ SequentialLR æˆ–åœ¨ scheduler å‰ç½® warmup è°ƒåº¦å™¨ã€‚
        warmup_iters = warmup_epochs * len(self.train_loader) if warmup_epochs > 0 else 0

        for batch_idx, batch in enumerate(pbar):
            # é€šè¿‡ preprocess_batch ç»Ÿä¸€ç§»åŠ¨å¹¶æ ¼å¼åŒ– batch
            images, batch_targets = self.preprocess_batch(batch)
            if images is None:
                # å›é€€åˆ°æ—§é€»è¾‘ï¼ˆä¿è¯å‘åå…¼å®¹ï¼‰
                images = batch['images'].to(self.device)
                batch_targets = {}
                for k, v in batch.items():
                    if isinstance(v, torch.Tensor):
                        batch_targets[k] = v.to(self.device)
                    else:
                        batch_targets[k] = v
            
            # å‰å‘ + åå‘ (AMP æ”¯æŒ)
            self.optimizer.zero_grad(set_to_none=True)
            # å…¼å®¹ä¸åŒ PyTorch ç‰ˆæœ¬çš„ autocast æ¥å£ (ä¼˜å…ˆæ–°API)
            try:  # æ–°ç‰ˆ (PyTorch >= 2.0) å»ºè®®ä½¿ç”¨ torch.amp.autocast
                from torch.amp import autocast as _autocast_new  # type: ignore
                autocast_ctx = _autocast_new(device_type='cuda', enabled=self.amp_enabled)
            except Exception:
                autocast_ctx = torch.cuda.amp.autocast(enabled=self.amp_enabled)
            with autocast_ctx:
                predictions = self.model(images)  # train: (det_out_list, kpt_raw)
                total_loss, loss_items = self.criterion(predictions, batch_targets)
                # åˆ†ç±»åˆ†å¸ƒç»Ÿè®¡ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
                if self.config.get('log_cls_stats', True):
                    try:
                        # ä» criterion å†…éƒ¨çš„ pred_cls æ— æ³•ç›´æ¥æ‹¿ï¼Œè¿™é‡Œå¿«é€Ÿå† decodeï¼š
                        # predictions è®­ç»ƒæ€ä¸‹æ¥è‡ª head: (det_out_list, kpt_raw)
                        if isinstance(predictions, (list, tuple)) and len(predictions) == 2:
                            det_out_list, _kpt_raw = predictions
                            # èšåˆåˆ†ç±» logits
                            cls_logits_all = []
                            for feat in det_out_list:
                                # feat: [B, no, H, W]; åˆ†ç±»åœ¨æœ€å 1 é€šé“ (reg_max*4 ä¹‹å)
                                reg_ch = self.criterion.reg_max * 4
                                cls_part = feat[:, reg_ch:, :, :].contiguous().view(feat.size(0), 1, -1)
                                cls_logits_all.append(cls_part)
                            cls_logits = torch.cat(cls_logits_all, dim=2)  # [B,1,N]
                            cls_probs = cls_logits.sigmoid()
                            cls_mean = cls_probs.mean().item()
                            cls_std = cls_probs.std().item()
                            cls_max = cls_probs.max().item()
                            # topk å¹³å‡ï¼ˆk=50 æˆ–æ‰€æœ‰ï¼‰
                            k = min(50, cls_probs.shape[-1])
                            topk_vals, _ = torch.topk(cls_probs.view(cls_probs.size(0), -1), k=k, dim=1)
                            topk_mean = topk_vals.mean().item()
                            if batch_idx % 50 == 0:
                                self.writer.add_scalar('Train/cls_prob_mean', cls_mean, self.global_iter)
                                self.writer.add_scalar('Train/cls_prob_std', cls_std, self.global_iter)
                                self.writer.add_scalar('Train/cls_prob_max', cls_max, self.global_iter)
                                self.writer.add_scalar('Train/cls_prob_topk_mean', topk_mean, self.global_iter)
                    except Exception:
                        pass

            if self.amp_enabled:
                self.scaler.scale(total_loss).backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10.0)
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                total_loss.backward()
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=10.0)
                self.optimizer.step()

            # Warmup çº¿æ€§å¢å¤§å­¦ä¹ ç‡
            if warmup_iters > 0 and self.global_iter < warmup_iters and self.base_lrs:
                ratio = (self.global_iter + 1) / warmup_iters
                for g, base_lr in zip(self.optimizer.param_groups, self.base_lrs or []):
                    try:
                        g['lr'] = base_lr * ratio
                    except Exception:
                        pass
            self.global_iter += 1
            
            # è®°å½•æŸå¤±
            losses.update(total_loss.item(), images.size(0))
            # åŠ¨æ€æŸå¤±åç§°
            loss_names = self.loss_names
            # loss_items contains 5 components (scaled by lambdas in PoseLoss)
            loss_meters = [bbox_losses, kpt_loc_losses, kpt_vis_losses, cls_losses, dfl_losses]
            for meter, loss_val in zip(loss_meters, loss_items[:5]):
                try:
                    meter.update(loss_val.item(), images.size(0))
                except Exception:
                    pass
            
            # æ›´æ–°æŒ‡æ ‡è·Ÿè¸ªå™¨æŸå¤±
            loss_dict = {
                'total_loss': total_loss.item(),
                **{name: loss_val.item() for name, loss_val in zip(loss_names, loss_items)}
            }
            self.metrics_tracker.update_losses(loss_dict)

            # æ›´æ–°å…³é”®ç‚¹æŒ‡æ ‡ (ä» raw è¾“å‡ºè§£ç ï¼Œé€å›¾ç»Ÿè®¡)
            try:
                # ä»…åœ¨è®­ç»ƒæ€ä¸‹ï¼Œpredictions ä¸º (det_out_list, kpt_raw)
                if isinstance(predictions, (tuple, list)) and len(predictions) == 2:
                    det_out_list, kpt_raw = predictions
                    # è§£ç ï¼Œç¡®ä¿ anchors/strides åˆå§‹åŒ–
                    try:
                        det_full = self.model.head._det_decode(det_out_list)  # [B,5,N]
                        kpt_dec = self.model.head._kpt_decode(images.size(0), kpt_raw)  # [B,63,N]
                        # é€‰æ‹©å•é”šç‚¹ï¼šä¸ head æ¨ç†ä¸€è‡´çš„ç»„åˆåˆ†æ•°
                        cls_scores = det_full[:, 4, :]  # [B,N]
                        vis_probs = kpt_dec[:, 2::3, :]  # [B,21,N]
                        vis_mean = vis_probs.mean(dim=1)  # [B,N]
                        combined = cls_scores * (vis_mean.clamp(0,1) ** 0.5)
                        comb_max, _ = combined.max(dim=1, keepdim=True)
                        comb_std = combined.std(dim=1, keepdim=True)
                        fallback_flag = (comb_max <= 1e-3) | (comb_std <= 1e-6)
                        max_idx = combined.argmax(dim=1, keepdim=True)
                        if fallback_flag.any():
                            max_idx_vis = vis_mean.argmax(dim=1, keepdim=True)
                            max_idx[fallback_flag] = max_idx_vis[fallback_flag]
                        # æŒ‰ç´¢å¼•é€‰å‡ºæ¯å›¾å…³é”®ç‚¹å¹¶é‡å¡‘ä¸º (B,21,3)
                        kpt_sel = self.model.head._select_single_target(kpt_dec, max_idx)  # [B,63,1]
                        kpt_sel = kpt_sel.squeeze(-1).view(kpt_sel.size(0), -1, 3)  # [B,21,3]

                        # æ„å»º GT æ¯å›¾å…³é”®ç‚¹ (ä¸ validator é€»è¾‘ä¸€è‡´, å½’ä¸€åŒ–åˆ° [0,1] çš„ letterbox ç›¸å¯¹åæ ‡)
                        B = images.size(0)
                        nk = getattr(self.model, 'nk', 21)
                        gt_kpts_per_image = torch.zeros((B, nk, 3), device=kpt_sel.device)
                        if 'batch_idx' in batch_targets and batch_targets['batch_idx'].numel() > 0 and batch_targets.get('keypoints') is not None:
                            obj_batch_idx = batch_targets['batch_idx']
                            kp_objs = batch_targets['keypoints']
                            for obj_i in range(obj_batch_idx.size(0)):
                                img_i = int(obj_batch_idx[obj_i].item())
                                if 0 <= img_i < B:
                                    gt_kpts_per_image[img_i] = kp_objs[obj_i].to(kpt_sel.device)

                        # å½’ä¸€åŒ–ä¸åƒç´ å•ä½åŒæ—¶æ›´æ–°
                        img_h = images.shape[2]; img_w = images.shape[3]
                        kpt_px = kpt_sel.clone()
                        kpt_norm = kpt_px.clone()
                        kpt_norm[:, :, 0] = kpt_norm[:, :, 0] / float(img_w)
                        kpt_norm[:, :, 1] = kpt_norm[:, :, 1] / float(img_h)

                        # è®­ç»ƒæŒ‡æ ‡ä¸­ä¸å†ç´¯è®¡å…³é”®ç‚¹ L1/å¯è§ç‚¹ç›¸å…³ç»Ÿè®¡
                    except Exception:
                        pass
            except Exception:
                pass
            
            # æ›´æ–°å­¦ä¹ ç‡åˆ°æŒ‡æ ‡è·Ÿè¸ªå™¨
            current_lr = self.optimizer.param_groups[0]['lr']
            self.metrics_tracker.update_lr(current_lr)
            
            # æ¯éš”ä¸€å®šæ­¥æ•°è¿›è¡ŒæŒ‡æ ‡è¯„ä¼° (ä¸ºäº†èŠ‚çœè®¡ç®—æ—¶é—´)
            # ç®€åŒ–ç‰ˆæœ¬: æš‚ä¸åšä¸­é€”é¢„æµ‹æŒ‡æ ‡ç»Ÿè®¡ï¼ˆå•ç›®æ ‡å›å½’ï¼‰
            
            # å®æ—¶æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤ºï¼ˆåŒ…å«åˆ†é¡¹æŸå¤±ï¼‰
            try:
                # ä½¿ç”¨æ›´çŸ­çš„é”®å¹¶æ ‡æ³¨ä¸ºå·²ä¹˜ç³»æ•°çš„å€¼ï¼ˆscaledï¼‰ï¼Œä»¥ä¾¿ä¸€çœ¼è¯†åˆ«è¿™æ˜¯ä¹˜è¿‡ lambda åçš„æŸå¤±
                # include cls* and dfl* which are also provided by PoseLoss
                pbar.set_postfix({
                    'L*': f'{losses.avg:.4f}',
                    'BBox*': f'{bbox_losses.avg:.4f}',
                    'KLoc*': f'{kpt_loc_losses.avg:.4f}',
                    'KVis*': f'{kpt_vis_losses.avg:.4f}',
                    'Cls*': f'{cls_losses.avg:.4f}',
                    'DFL*': f'{dfl_losses.avg:.4f}',
                    'LR': f'{current_lr:.6f}'
                })
            except Exception:
                # ä¿é™©å›é€€åˆ°ä»…æ˜¾ç¤ºæ€»æŸå¤±
                try:
                    pbar.set_postfix({'Loss': f'{losses.avg:.4f}', 'LR': f'{current_lr:.6f}'})
                except Exception:
                    pass
            
            # TensorBoardè®°å½•
            if batch_idx % 10 == 0:
                step = epoch * len(self.train_loader) + batch_idx
                self.writer.add_scalar('Train/Loss', total_loss.item(), step)
                self.writer.add_scalar('Train/LearningRate', current_lr, step)
                
                for i, (name, loss_val) in enumerate(zip(loss_names, loss_items)):
                    if hasattr(loss_val, 'item'):
                        self.writer.add_scalar(f'Train/{name}', loss_val.item(), step)
        
        # å…³é—­è¿›åº¦æ¡
        pbar.close()
        
        # æ¢è¡Œåè®°å½•è¯¦ç»†çš„æŸå¤±ä¿¡æ¯
        logger.info("Epoch %d Training Results:", epoch+1)
        logger.info("   Total Loss: %.6f", losses.avg)
        logger.info("   BBox Loss:  %.6f", bbox_losses.avg)
        logger.info("   Kpt Loc:    %.6f", kpt_loc_losses.avg)
        logger.info("   Kpt Vis:    %.6f", kpt_vis_losses.avg)
        logger.info("   Cls Loss:   %.6f", cls_losses.avg)
        logger.info("   DFL Loss:   %.6f", dfl_losses.avg)
        logger.info("   LR:         %.8f", current_lr)

        # è®­ç»ƒé˜¶æ®µä¸å†ç»Ÿè®¡/è®°å½•å…³é”®ç‚¹è¾…åŠ©æŒ‡æ ‡ï¼ˆæŒ‰éœ€æ±‚åˆ é™¤ï¼‰

        # ç»“æŸepochæŒ‡æ ‡ç»Ÿè®¡
        self.metrics_tracker.end_epoch()
        train_stats = {
            'train_total_loss': losses.avg,
            'train_bbox_loss': bbox_losses.avg,
            'train_kpt_loc_loss': kpt_loc_losses.avg,
            'train_kpt_vis_loss': kpt_vis_losses.avg,
            'train_cls_loss': cls_losses.avg,
            'train_dfl_loss': dfl_losses.avg,
            'lr': current_lr
        }
        return train_stats

    
    # _extract_predictions_for_metrics å·²ç§»é™¤ï¼ˆå•ç›®æ ‡ç®€åŒ–ä¸éœ€è¦ï¼‰
    
    def validate(self, epoch):
        """éªŒè¯ - è°ƒç”¨å¤–éƒ¨éªŒè¯å™¨å¹¶é›†æˆæŒ‡æ ‡è·Ÿè¸ª"""
        logger.info("ğŸ” Validating Epoch %d...", epoch+1)

        val_loss, metrics = self.validater.validate_epoch(
            self.val_loader,
            epoch=epoch,
            verbose=True  # è®©éªŒè¯å™¨æ˜¾ç¤ºè¿›åº¦æ¡
        )

        # æ¢è¡Œåè®°å½•éªŒè¯ç»“æœ
        logger.info("ğŸ“ˆ Epoch %d Validation Results:", epoch+1)
        logger.info("   Val Loss:   %.6f", val_loss)
        if metrics:
            for key, value in metrics.items():
                if isinstance(value, (int, float)):
                    logger.info("   %s: %.6f", key, value)

        # ä¸å†è®°å½•è®­ç»ƒé˜¶æ®µå…³é”®ç‚¹ L1 åˆ°éªŒè¯é¢æ¿

        # TensorBoardè®°å½•ï¼šVal/Loss ç”± Trainer å†™å…¥ï¼›ç»†åˆ† Val/* æŒ‡æ ‡ç”± Validater ç»Ÿä¸€å†™å…¥ï¼Œé¿å…é‡å¤
        self.writer.add_scalar('Val/Loss', val_loss, epoch)

        # æ›´æ–°æœ€ä½³æŒ‡æ ‡åˆ°è·Ÿè¸ªå™¨
        self.metrics_tracker.training_metrics.update_best_metrics(metrics)

        # è‡ªåŠ¨ä¿å­˜ per-image éªŒè¯ç»“æœä¸º CSVï¼ˆé»˜è®¤å¯ç”¨ï¼Œå¯åœ¨ config ä¸­å…³é—­ï¼‰
        try:
            if self.config.get('save_val_per_image_csv', True):
                csv_dir = os.path.join(self.config['save_dir'], 'validation')
                os.makedirs(csv_dir, exist_ok=True)
                csv_path = os.path.join(csv_dir, f'val_per_image_epoch{epoch+1}.csv')
                try:
                    self.validater.save_validation_csv(csv_path)
                    logger.info("Saved per-image validation CSV: %s", csv_path)
                except Exception:
                    logger.exception("ä¿å­˜ per-image CSV å¤±è´¥: %s", csv_path)
        except Exception:
            logger.exception("å°è¯•ä¿å­˜ per-image CSV æ—¶å‘ç”Ÿé”™è¯¯")

        return val_loss, metrics
    
    def evaluate_model(self):
        """ä½¿ç”¨éªŒè¯å™¨è¿›è¡Œè½»é‡è¯„ä¼° (è¿”å›éªŒè¯æŸå¤±ä¸æŒ‡æ ‡)ã€‚"""
        if not hasattr(self, 'val_loader'):
            self.setup_data_loaders()
        return self.validater.evaluate_model(self.val_loader, epoch=0)
    
    def save_checkpoint(self, epoch, loss, metrics, is_best=False):
        """ä¿å­˜ last + (å¯é€‰) best æ£€æŸ¥ç‚¹ï¼ŒåŒ…å«éšæœºä¸ AMP çŠ¶æ€"""
        ckpt_dir = os.path.join(self.config['save_dir'], 'weights')
        os.makedirs(ckpt_dir, exist_ok=True)
        state = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict() if self.scheduler else None,
            'loss': loss,
            'metrics': metrics,
            'config': self.config,
            'best_loss': self.best_loss,
            'best_metric_name': self.best_metric_name,
            'best_metric_value': self.best_metric_value,
            'best_metric_mode': self.best_metric_mode,
            'best_metric_delta': self.best_metric_delta,
            'best_metric_epoch': self.best_metric_epoch,
            'amp': self.amp_enabled,
            'scaler': self.scaler.state_dict() if self.amp_enabled else None,
            'rng_state': torch.get_rng_state(),
            'numpy_rng_state': np.random.get_state(),
            'python_rng_state': random.getstate()
        }
        if torch.cuda.is_available():
            state['cuda_rng_state_all'] = torch.cuda.get_rng_state_all()
        last_path = os.path.join(ckpt_dir, 'last.pt')
        try:
            torch.save(state, last_path)
        except Exception:
            logger.exception("ä¿å­˜ last å¤±è´¥: %s", last_path)
        # åŒæ—¶å¯é€‰åœ°ä¿å­˜ä¸€ä¸ªä»…åŒ…å« model.state_dict() çš„è½»é‡çº§å‰¯æœ¬ï¼Œä¾¿äºç›´æ¥å¯¹æ¯”/æ›¿æ¢
        try:
            save_weights_only = bool(self.config.get('save_weights_only_copy', True))
        except Exception:
            save_weights_only = True

        if save_weights_only:
            try:
                last_weights_path = os.path.join(ckpt_dir, 'last_weights.pt')
                torch.save(self.model.state_dict(), last_weights_path)
            except Exception:
                logger.exception("ä¿å­˜ last_weights å¤±è´¥: %s", last_weights_path)

        if is_best:
            best_path = os.path.join(ckpt_dir, 'best.pt')
            try:
                torch.save(state, best_path)
                logger.info("æ–°çš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜: %s (Val Loss: %.6f)", best_path, loss)
            except Exception as e:
                logger.exception("ä¿å­˜ best å¤±è´¥: %s", best_path)
            if save_weights_only:
                try:
                    best_weights_path = os.path.join(ckpt_dir, 'best_weights.pt')
                    torch.save(self.model.state_dict(), best_weights_path)
                except Exception:
                    logger.exception("ä¿å­˜ best_weights å¤±è´¥: %s", best_weights_path)
    
    def load_checkpoint(self, checkpoint_path):
        """åŠ è½½æ£€æŸ¥ç‚¹å¹¶æ¢å¤è®­ç»ƒ/éšæœº/AMPçŠ¶æ€"""
        if not os.path.isfile(checkpoint_path):
            logger.error("æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸å­˜åœ¨: %s", checkpoint_path)
            return False

        logger.info("åŠ è½½æ£€æŸ¥ç‚¹: %s", checkpoint_path)
        try:
            # é¦–å…ˆå°è¯•å®Œæ•´åŠ è½½
            ckpt = torch.load(checkpoint_path, map_location=self.device)

            # åˆ¤æ–­æ˜¯å®Œæ•´ checkpoint (åŒ…å« epoch/optimizer ç­‰) è¿˜æ˜¯ä»… weights/state_dict
            if isinstance(ckpt, dict) and ('epoch' in ckpt or 'optimizer_state_dict' in ckpt or 'best_loss' in ckpt):
                full_ckpt = True
            else:
                full_ckpt = False

            if full_ckpt:
                state_dict = ckpt.get('model_state_dict') or ckpt.get('state_dict') or ckpt
            else:
                # è¿™æ˜¯ä¸€ä¸ªä»…åŒ…å« state_dict çš„æ–‡ä»¶ï¼ˆæˆ–çº¯æƒé‡å­—å…¸ï¼‰
                state_dict = ckpt
                logger.info("æ£€æµ‹åˆ° weights-only checkpointï¼Œä»…åŠ è½½æ¨¡å‹æƒé‡")

            if not isinstance(state_dict, dict):
                logger.warning("æ£€æŸ¥ç‚¹ä¸åŒ…å«æœ‰æ•ˆçš„ state_dictï¼Œå°è¯•æŒ‰çº¯æƒé‡å­—å…¸è§£æ")
            self.model.load_state_dict(state_dict, strict=False)

            # ä¼˜åŒ–å™¨ç­‰å¯é€‰
            if full_ckpt:
                opt_state = ckpt.get('optimizer_state_dict')
                if opt_state:
                    try:
                        self.optimizer.load_state_dict(opt_state)
                    except Exception:
                        logger.exception("ä¼˜åŒ–å™¨çŠ¶æ€æ¢å¤å¤±è´¥(å¿½ç•¥)")
                sch_state = ckpt.get('scheduler_state_dict')
                if sch_state and self.scheduler:
                    try:
                        self.scheduler.load_state_dict(sch_state)
                    except Exception:
                        logger.exception("è°ƒåº¦å™¨çŠ¶æ€æ¢å¤å¤±è´¥(å¿½ç•¥)")
                if self.amp_enabled and ckpt.get('scaler'):
                    try:
                        self.scaler.load_state_dict(ckpt['scaler'])
                    except Exception:
                        logger.warning("AMP scaler çŠ¶æ€æ¢å¤å¤±è´¥(å¿½ç•¥)")

                self.start_epoch = ckpt.get('epoch', -1) + 1
                self.best_loss = ckpt.get('best_loss', self.best_loss)
            else:
                # weights-only æ–‡ä»¶: ä¸èƒ½æ¢å¤ä¼˜åŒ–å™¨/epoch ç­‰ï¼Œç”¨æˆ·åº”ä» epoch 0 é‡æ–°è®­ç»ƒæˆ–æ‰‹åŠ¨è®¾ç½®
                self.start_epoch = 0

            # éšæœºçŠ¶æ€æ¢å¤ï¼ˆç±»å‹æ£€æŸ¥ï¼‰
            try:
                rng_state = ckpt.get('rng_state')
                if rng_state is not None:
                    try:
                        torch.set_rng_state(rng_state)
                    except Exception:
                        logger.warning("æ— æ³•æ¢å¤ torch RNG stateï¼Œç±»å‹: %s", type(rng_state))
            except Exception:
                logger.exception("RNG çŠ¶æ€æ¢å¤å¤±è´¥(è·³è¿‡)")

            try:
                np_state = ckpt.get('numpy_rng_state')
                if np_state is not None:
                    np.random.set_state(np_state)
            except Exception:
                logger.warning("numpy éšæœºçŠ¶æ€æ¢å¤å¤±è´¥(å¿½ç•¥)")

            try:
                py_state = ckpt.get('python_rng_state')
                if py_state is not None:
                    random.setstate(py_state)
            except Exception:
                logger.warning("python éšæœºçŠ¶æ€æ¢å¤å¤±è´¥(å¿½ç•¥)")

            if ckpt.get('cuda_rng_state_all') and torch.cuda.is_available():
                try:
                    torch.cuda.set_rng_state_all(ckpt['cuda_rng_state_all'])
                except Exception:
                    logger.warning("CUDA RNG çŠ¶æ€æ¢å¤å¤±è´¥(å¿½ç•¥)")

            logger.info("æˆåŠŸåŠ è½½æ£€æŸ¥ç‚¹(æƒé‡+éƒ¨åˆ†çŠ¶æ€)ï¼Œä» epoch %d ç»§ç»­", self.start_epoch)
            return True

        except Exception:
            logger.exception("åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: %s", checkpoint_path)
            logger.info("å›é€€: ä»…å°è¯•åŠ è½½æ¨¡å‹æƒé‡ (strict=False)")
            try:
                weights = torch.load(checkpoint_path, map_location=self.device)
                if isinstance(weights, dict):
                    cand = weights.get('model_state_dict') or weights.get('state_dict') or weights
                    if isinstance(cand, dict):
                        try:
                            self.model.load_state_dict(cand, strict=False)
                            logger.info("ä»…æƒé‡åŠ è½½æˆåŠŸï¼Œé‡æ–°ä» epoch 0 è®­ç»ƒ")
                            self.start_epoch = 0
                            return True
                        except Exception:
                            logger.exception("ä»…æƒé‡åŠ è½½ä¹Ÿå¤±è´¥: %s", checkpoint_path)
            except Exception:
                logger.exception("å°è¯•ä»…æƒé‡åŠ è½½ä¹Ÿå¤±è´¥: %s", checkpoint_path)
            return False
    
    def train(self, resume_from=None):
        """
        å¼€å§‹è®­ç»ƒ
        
        Args:
            resume_from: æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„
        """
        logger.info("å¼€å§‹è®­ç»ƒï¼Œè®¾å¤‡: %s", self.device)

        # è®¾ç½®æ•°æ®åŠ è½½å™¨ - å¦‚æœå¤±è´¥ä¼šç›´æ¥æŠ›å‡ºå¼‚å¸¸
        self.setup_data_loaders()
        
        # æ¢å¤è®­ç»ƒ
        if resume_from:
            self.load_checkpoint(resume_from)
        
        start_time = time.time()
        
        try:
            # CSV å¤´éƒ¨æ˜¯å¦å·²å†™
            csv_header_written = os.path.exists(self.csv_path)
            metric_header_keys = None  # è®°å½•éªŒè¯æŒ‡æ ‡åˆ—é¡ºåº

            for epoch in range(self.start_epoch, self.config['epochs']):
                epoch_start_time = time.time()

                # è®­ç»ƒ
                train_stats = self.train_epoch(epoch)
                train_loss = train_stats['train_total_loss']
                self.train_losses.append(train_loss)

                # é¢„è®¾éªŒè¯å ä½
                val_loss = None
                metrics = {}

                performed_val = False
                if epoch % self.config['val_interval'] == 0:
                    val_loss, metrics = self.validate(epoch)
                    self.val_losses.append(val_loss)
                    performed_val = True
                    # å§‹ç»ˆç»´æŠ¤ best_loss (å…¼å®¹)
                    if val_loss < self.best_loss:
                        self.best_loss = val_loss

                    monitor_key = self.best_metric_name or 'val_loss'
                    if monitor_key == 'val_loss':
                        monitor_val = val_loss
                    else:
                        monitor_val = metrics.get(monitor_key)
                        if monitor_val is None:
                            logger.warning("early_stop_metric '%s' ä¸å­˜åœ¨äºå½“å‰ metrics, å›é€€ä½¿ç”¨ val_loss", monitor_key)
                            monitor_key = 'val_loss'
                            monitor_val = val_loss

                    improved = False
                    if self.best_metric_value is None:
                        improved = True
                    else:
                        if self.best_metric_mode == 'min':
                            improved = (monitor_val < self.best_metric_value - self.best_metric_delta)
                        else:
                            improved = (monitor_val > self.best_metric_value + self.best_metric_delta)

                    if improved:
                        self.best_metric_value = float(monitor_val)
                        self.best_metric_epoch = epoch
                        self.patience_counter = 0
                        is_best = True
                    else:
                        self.patience_counter += 1
                        is_best = False

                    if self.early_stop_enabled and self.patience_counter >= self.config['patience']:
                        logger.info(
                            "âš ï¸  Early stopping on %s (%s mode, Î”<=%.4f) no improvement for %d epochs | best=%.6f @ epoch %s",
                            monitor_key, self.best_metric_mode, self.best_metric_delta, self.config['patience'],
                            self.best_metric_value if self.best_metric_value is not None else float('nan'),
                            (self.best_metric_epoch+1) if self.best_metric_epoch is not None else 'N/A'
                        )
                        self.save_checkpoint(epoch, val_loss, metrics, is_best)
                        if self.config.get('save_csv', True):
                            self._append_results_csv(epoch, train_stats, val_loss, metrics,
                                                     csv_header_written, metric_header_keys)
                        break

                    # ä¿å­˜æ”¹è¿›æ¨¡å‹
                    self.save_checkpoint(epoch, val_loss, metrics, is_best)

                # æ›´æ–°å­¦ä¹ ç‡ï¼ˆæ”¾åœ¨éªŒè¯åï¼Œä¿æŒä¸å¤§å¤šæ•°å®è·µä¸€è‡´ï¼‰
                self.scheduler.step()

                # è®­ç»ƒæœŸå…³é”®ç‚¹è¦†ç›–å›¾åŠŸèƒ½å·²ç§»é™¤ï¼Œé¿å…æ— æ•ˆåˆ†æ”¯ä¸æ··æ·†

                # å†™å…¥ / è¿½åŠ  CSV ï¼ˆåŒ…å«éªŒè¯åˆ—ï¼‰
                if self.config.get('save_csv', True):
                    # é¦–æ¬¡éªŒè¯æ—¶å»ºç«‹æŒ‡æ ‡åˆ—é¡ºåº
                    if performed_val and metric_header_keys is None:
                        metric_header_keys = [k for k, v in metrics.items() if isinstance(v, (int, float, np.number))]
                    self._append_results_csv(epoch, train_stats, val_loss if performed_val else None, metrics,
                                             csv_header_written, metric_header_keys)
                    csv_header_written = True

                # Persist epoch losses to JSON (one file for easy plotting & inspection)
                try:
                    self._save_epoch_losses_json(epoch+1, train_loss, val_loss if performed_val else None)
                except Exception:
                    logger.exception("å†™å…¥ epoch_losses.json å¤±è´¥")

                # æ‰“å°æ€»ç»“
                self._print_epoch_summary(epoch, train_loss, epoch_start_time, start_time)
                
        except KeyboardInterrupt:
            logger.warning("è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            logger.exception("è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: %s", e)
        finally:
            self.writer.close()
            logger.info('è®­ç»ƒç»“æŸï¼')
            
            # æ‰“å°æœ€ç»ˆè®­ç»ƒæ€»ç»“
            self._print_final_summary()

    def _append_results_csv(self, epoch, train_stats, val_loss, val_metrics, header_written, metric_keys):
        """å°†å•ä¸ª epoch çš„è®­ç»ƒä¸éªŒè¯ç»“æœå†™å…¥ CSVã€‚

    åˆ—ç»“æ„:
    epoch,train_total_loss,train_bbox_loss,train_kpt_loc_loss,train_kpt_vis_loss,train_cls_loss,train_dfl_loss,
    val_total_loss,val_bbox_loss,val_kpt_loc_loss,val_kpt_vis_loss,val_cls_loss,val_dfl_loss,
    lr,<val_metric_1>...
        ä»…å½“æœ¬ epoch è¿›è¡Œäº†éªŒè¯æ‰å†™å…¥ val_loss ä¸æŒ‡æ ‡, å¦åˆ™ä¸ºç©ºã€‚
        """
        try:
            os.makedirs(os.path.dirname(self.csv_path), exist_ok=True)
            # æ„å»ºå­—æ®µå­—å…¸ï¼Œä¾¿äºä¸æ—¢æœ‰å¤´å¯¹é½æˆ–ç”Ÿæˆæ–°å¤´
            fields = {}
            # epoch
            fields['epoch'] = str(epoch+1)
            # è®­ç»ƒæŸå¤±
            fields['train_total_loss'] = f"{train_stats['train_total_loss']:.6f}"
            fields['train_bbox_loss'] = f"{train_stats.get('train_bbox_loss',0.0):.6f}"
            fields['train_kpt_loc_loss'] = f"{train_stats.get('train_kpt_loc_loss',0.0):.6f}"
            fields['train_kpt_vis_loss'] = f"{train_stats.get('train_kpt_vis_loss',0.0):.6f}"
            fields['train_cls_loss'] = f"{train_stats.get('train_cls_loss',0.0):.6f}"
            fields['train_dfl_loss'] = f"{train_stats.get('train_dfl_loss',0.0):.6f}"
            # å­¦ä¹ ç‡
            fields['lr'] = f"{train_stats['lr']:.8f}"

            # éªŒè¯æŸå¤±
            if val_loss is not None:
                fields['val_total_loss'] = f"{val_loss:.6f}"
                fields['val_loss'] = f"{val_loss:.6f}"  # å…¼å®¹æ—§åˆ—å
                if isinstance(val_metrics, dict):
                    def fmt(v):
                        return f"{float(v):.6f}" if isinstance(v,(int,float,np.number)) else ""
                    fields['val_bbox_loss'] = fmt(val_metrics.get('bbox_loss'))
                    fields['val_kpt_loc_loss'] = fmt(val_metrics.get('kpt_loc_loss'))
                    fields['val_kpt_vis_loss'] = fmt(val_metrics.get('kpt_vis_loss'))
                    fields['val_cls_loss'] = fmt(val_metrics.get('cls_loss'))
                    fields['val_dfl_loss'] = fmt(val_metrics.get('dfl_loss'))
                    # å…¶å®ƒéªŒè¯æŒ‡æ ‡
                    miou = val_metrics.get('mean_iou')
                    if isinstance(miou,(int,float,np.number)):
                        fields['val_mean_iou'] = f"{float(miou):.6f}"
                    # æ¯å…³é”®ç‚¹ MAE
                    for i in range(getattr(self.model, 'nk', 21)):
                        key = f'kpt_{i}_mae'
                        v = val_metrics.get(key)
                        fields['val_'+key] = f"{float(v):.6f}" if isinstance(v,(int,float,np.number)) else ""
                    # å…¶å®ƒæ•°å€¼å‹ metricsï¼Œé¿å…é‡å¤
                    if metric_keys:
                        for k in metric_keys:
                            if k in ('mean_iou','bbox_loss','kpt_loc_loss','kpt_vis_loss','cls_loss','dfl_loss') or k.startswith('kpt_'):
                                continue
                            v = val_metrics.get(k)
                            if isinstance(v,(int,float,np.number)):
                                fields['val_'+k] = f"{float(v):.6f}"

            # å¦‚æœå·²æœ‰å¤´ï¼ŒæŒ‰ç°æœ‰åˆ—å¯¹é½ï¼›å¦åˆ™å†™æ–°å¤´ï¼ˆæ–°é¡ºåºæ»¡è¶³ä½ çš„è¦æ±‚ï¼‰
            if header_written:
                with open(self.csv_path,'r',encoding='utf-8') as f:
                    existing_header = f.readline().strip()
                existing_cols = existing_header.split(',') if existing_header else []
                line_parts = [fields.get(col, '') for col in existing_cols]
                header_cols = existing_cols
            else:
                header_cols = [
                    'epoch',
                    'train_total_loss','train_bbox_loss','train_kpt_loc_loss','train_kpt_vis_loss','train_cls_loss','train_dfl_loss',
                    'val_total_loss','val_bbox_loss','val_kpt_loc_loss','val_kpt_vis_loss','val_cls_loss','val_dfl_loss',
                    'lr',
                    'val_mean_iou',
                ]
                # é€ä¸ªè¿½åŠ  val_kpt_i_mae
                header_cols.extend([f'val_kpt_{i}_mae' for i in range(getattr(self.model, 'nk', 21))])
                # è¿½åŠ å…¶å®ƒ val_* æŒ‡æ ‡ï¼ˆè‹¥ metric_keys æŒ‡å®šï¼‰
                if metric_keys:
                    for k in metric_keys:
                        if k in ('mean_iou','bbox_loss','kpt_loc_loss','kpt_vis_loss','cls_loss','dfl_loss') or k.startswith('kpt_'):
                            continue
                        col = 'val_'+k
                        if col not in header_cols:
                            header_cols.append(col)
                line_parts = [fields.get(col, '') for col in header_cols]

            # å†™æ–‡ä»¶
            with open(self.csv_path,'a',encoding='utf-8') as f:
                if not header_written:
                    f.write(','.join(header_cols)+'\n')
                f.write(','.join(line_parts)+'\n')
        except Exception as e:
            logger.exception("å†™å…¥ CSV å¤±è´¥: %s", e)

    def _save_epoch_losses_json(self, epoch: int, train_loss: float, val_loss):
        """Append epoch loss record to a JSON file.

        The file stores a list of records, each:
            {"epoch": int, "train_loss": float, "val_loss": float|null, "timestamp": "..."}

        Args:
            epoch: 1-based epoch index
            train_loss: training loss value
            val_loss: validation loss value or None
        """
        try:
            os.makedirs(os.path.dirname(self.epoch_losses_path), exist_ok=True)
            # load existing
            records = []
            if os.path.exists(self.epoch_losses_path):
                try:
                    with open(self.epoch_losses_path, 'r', encoding='utf-8') as f:
                        records = json.load(f) or []
                except Exception:
                    # corrupt or unreadable -> back up and start fresh
                    try:
                        backup = self.epoch_losses_path + ".bak"
                        os.replace(self.epoch_losses_path, backup)
                    except Exception:
                        pass
                    records = []

            import datetime
            rec = {
                'epoch': int(epoch),
                'train_loss': float(train_loss) if train_loss is not None else None,
                'val_loss': float(val_loss) if val_loss is not None else None,
                'timestamp': datetime.datetime.now().isoformat()
            }
            records.append(rec)
            # atomic write
            tmp_path = self.epoch_losses_path + '.tmp'
            with open(tmp_path, 'w', encoding='utf-8') as f:
                json.dump(records, f, ensure_ascii=False, indent=2)
            os.replace(tmp_path, self.epoch_losses_path)
        except Exception:
            logger.exception("æ— æ³•å†™å…¥ epoch losses JSON")
    
    def _print_epoch_summary(self, epoch, train_loss, epoch_start_time, total_start_time):
        """ç®€åŒ–çš„epochæ€»ç»“"""
        epoch_time = time.time() - epoch_start_time
        elapsed_time = time.time() - total_start_time
        remaining_epochs = self.config['epochs'] - epoch - 1
        remaining_time = elapsed_time * remaining_epochs / (epoch - self.start_epoch + 1) if epoch > self.start_epoch else 0
        
        logger.info("â±ï¸  Epoch %d/%d Summary:", epoch+1, self.config['epochs'])
        logger.info("   Time: %.1fs | Elapsed: %.1fh | ETA: %.1fh", epoch_time, elapsed_time/3600.0, remaining_time/3600.0)
        
        # éªŒè¯æŸå¤±å’Œæ—©åœä¿¡æ¯
        if self.val_losses:
            if self.early_stop_enabled:
                metric_str = f"{self.best_metric_name}={self.best_metric_value:.6f}" if self.best_metric_value is not None else "N/A"
                logger.info("   Best Loss: %.6f | Monitored(%s,%s): %s | Patience %d/%d",
                            self.best_loss, self.best_metric_mode, f"Î”>{self.best_metric_delta}" if self.best_metric_delta>0 else 'Î”>0',
                            metric_str, self.patience_counter, self.config['patience'])
            else:
                logger.info("   Best Loss: %.6f | Early Stop: disabled", self.best_loss)
            
        logger.info("%s", "-" * 60)
    
    def _print_final_summary(self):
        """æ‰“å°æœ€ç»ˆè®­ç»ƒæ€»ç»“"""
        logger.info("%s", '='*80)
        logger.info("è®­ç»ƒå®Œæˆæ€»ç»“")
        logger.info("%s", '='*80)
        
        # åŸºæœ¬ç»Ÿè®¡
        total_epochs = len(self.train_losses)
        logger.info("æ€»å…±è®­ç»ƒ: %d epochs", total_epochs)
        logger.info("æœ€ä½³éªŒè¯æŸå¤±: %.4f", self.best_loss)
        
        if self.train_losses:
            logger.info("æœ€ç»ˆè®­ç»ƒæŸå¤±: %.4f", self.train_losses[-1])
            logger.info("æœ€ä½³è®­ç»ƒæŸå¤±: %.4f", min(self.train_losses))
        
        if self.val_losses:
            logger.info("æœ€ç»ˆéªŒè¯æŸå¤±: %.4f", self.val_losses[-1])
        if self.best_metric_value is not None:
            logger.info("ç›‘æ§æŒ‡æ ‡ %s (%s) æœ€ä½³å€¼: %.6f (epoch %s)",
                        self.best_metric_name, self.best_metric_mode,
                        self.best_metric_value,
                        (self.best_metric_epoch+1) if self.best_metric_epoch is not None else 'N/A')
        
        # è·å–å®Œæ•´çš„è®­ç»ƒæ€»ç»“
        try:
            final_metrics = self.metrics_tracker.compute_all_metrics()
            training_summary = final_metrics.get('training_summary', {}) if isinstance(final_metrics, dict) else {}

            if isinstance(training_summary, dict):
                logger.info("è®­ç»ƒæ•ˆç‡ç»Ÿè®¡:")
                total_time_hours = training_summary.get('total_time_hours', 0.0)
                avg_epoch_time_minutes = training_summary.get('avg_epoch_time_minutes', 0.0)
                logger.info("  æ€»è®­ç»ƒæ—¶é—´: %.2f å°æ—¶", total_time_hours)
                logger.info("  å¹³å‡æ¯epochæ—¶é—´: %.1f åˆ†é’Ÿ", avg_epoch_time_minutes)

                best_metrics = training_summary.get('best_metrics', {})
                if isinstance(best_metrics, dict) and best_metrics:
                    logger.info("éªŒè¯è¿‡ç¨‹ä¸­çš„æœ€ä½³æŒ‡æ ‡:")
                    for key, value in best_metrics.items():
                        try:
                            logger.info("  %s: %.4f", key, float(value))
                        except Exception:
                            logger.info("  %s: %s", key, value)
            
        except Exception:
            logger.exception("è·å–è®­ç»ƒæ€»ç»“æ—¶å‡ºé”™")
        
        logger.info("%s", '='*80)
    
    def get_training_summary(self):
        """è·å–è®­ç»ƒæ€»ç»“"""
        return {
            'total_epochs': len(self.train_losses),
            'best_loss': self.best_loss,
            'final_train_loss': self.train_losses[-1] if self.train_losses else None,
            'final_val_loss': self.val_losses[-1] if self.val_losses else None,
            'train_losses': self.train_losses,
            'val_losses': self.val_losses
        }

    # è®¾å®šéšæœºç§å­
    def _set_seed(self, seed):
        if seed is None:
            return
        try:
            random.seed(seed)
            np.random.seed(seed)
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed_all(seed)
        except Exception:
            logger.exception("è®¾å®šéšæœºç§å­å¤±è´¥")



