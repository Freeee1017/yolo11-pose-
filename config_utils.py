#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""ç»Ÿä¸€çš„é…ç½®åŠ è½½ä¸è®­ç»ƒé…ç½®å·¥å…·

æä¾›:
- load_config: è¯»å– config.yamlï¼Œè¿”å› dictï¼›æ–‡ä»¶ä¸å­˜åœ¨æˆ–è§£æå¤±è´¥æ—¶ç»™å‡ºé»˜è®¤å€¼å¹¶æ‰“å°æç¤º
- load_training_config: åœ¨ load_config åŸºç¡€ä¸Šåˆå¹¶é»˜è®¤å€¼å¹¶æ”¯æŒè¦†ç›–ï¼ˆCLI/debugç­‰ï¼‰
- validate_config: æ ¡éªŒå…³é”®è·¯å¾„ä¸æ ¸å¿ƒå‚æ•°èŒƒå›´
- print_config_summary: å‹å¥½çš„é…ç½®æ‘˜è¦æ‰“å°
- check_environment: è®­ç»ƒç¯å¢ƒå¿«é€Ÿæ£€æŸ¥ï¼ˆGPUã€å¯é€‰ç›®å½•åˆ›å»ºï¼‰
- set_seed: ç»Ÿä¸€çš„éšæœºç§å­è®¾ç½®
- create_experiment_name: æ ¹æ®é…ç½®ç”Ÿæˆå®éªŒåç§°

å°½é‡å°†é€šç”¨é€»è¾‘é›†ä¸­ï¼Œé¿å… my_train æˆ–å…¶ä»–æ¨¡å—é‡å¤å®ç°ã€‚
"""
from __future__ import annotations
import os
import yaml
from typing import Dict, Any, Optional
import torch
import numpy as np
import datetime

# å…¨å±€é»˜è®¤é…ç½®ï¼Œå¯æŒ‰éœ€æ‰©å±•
DEFAULT_CONFIG: Dict[str, Any] = {
    'epochs': 300,
    'lr': 0.001,
    'weight_decay': 0.0005,
    'batch_size': 8,
    'img_size': 640,
    'num_workers': 4,
    'seed': 42,
    # data path specific keys (present in config.yaml)
    'train_img_dir': 'dataset/images/train',
    'train_label_dir': 'dataset/labels/train',
    'val_img_dir': 'dataset/images/val',
    'val_label_dir': 'dataset/labels/val',
    # augmentation probabilities / ranges (from config.yaml)
    'horizontal_flip_prob': 0.5,
    'rotation_prob': 0.3,
    'rotation_range': 15.0,
    'scale_prob': 0.3,
    'scale_range': [0.9, 1.1],
    'translation_prob': 0.3,
    'translation_range': 0.05,
    'color_prob': 0.4,
    'brightness_range': 0.1,
    'contrast_range': 0.1,
    # training schedule / lr strategy (from config.yaml)
    'warmup_epochs': 3,
    # loss related optional keys
    'lambda_box': 7.5,
    'lambda_cls': 0.5,
    'lambda_kpt': 12.0,
    'lambda_kpt_vis': 1.0,
    'lambda_dfl': 1.5,
    'nk': 21,
    'nc': 1,
    'classes': ['baby'],
}

def load_config(path: str = "config.yaml", merge_default: bool = True) -> Dict[str, Any]:
    """åŠ è½½ YAML é…ç½®ã€‚å¤±è´¥æ—¶è¿”å›é»˜è®¤é…ç½®ï¼ˆæˆ–ç©ºå­—å…¸ï¼‰ã€‚
    Args:
        path: é…ç½®æ–‡ä»¶è·¯å¾„
        merge_default: æ˜¯å¦å°†è¯»å–ç»“æœä¸ DEFAULT_CONFIG åˆå¹¶ï¼ˆä¼˜å…ˆç”¨æˆ·å€¼ï¼‰
    Returns:
        dict
    """
    data: Dict[str, Any] = {}
    if os.path.exists(path):
        try:
            with open(path, 'r', encoding='utf-8') as f:
                loaded = yaml.safe_load(f) or {}
            if not isinstance(loaded, dict):
                print(f"é…ç½®æ–‡ä»¶æ ¼å¼å¼‚å¸¸(éå­—å…¸)ï¼Œå¿½ç•¥: {path}")
                loaded = {}
            data = loaded
        except Exception as e:
            print(f"è¯»å–é…ç½®å¤±è´¥: {e} -> ä½¿ç”¨é»˜è®¤é…ç½®")
    else:
        # é™é»˜ï¼šè®­ç»ƒåˆæœŸå¯èƒ½è¿˜æ²¡å†™ config.yaml
        pass
    if merge_default:
        merged = DEFAULT_CONFIG.copy()
        merged.update(data)
        return merged
    return data

def load_training_config(config_path: str = "config.yaml", overrides: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
    """åŠ è½½è®­ç»ƒé…ç½®ï¼Œåˆå¹¶ DEFAULT_CONFIG ä¸ YAMLï¼Œå¹¶åº”ç”¨å¯é€‰è¦†ç›–ã€‚

    Args:
        config_path: é…ç½®æ–‡ä»¶è·¯å¾„
        overrides: é¢å¤–è¦†ç›–ï¼ˆä¾‹å¦‚æ¥è‡ª CLI çš„ debug/early_stop å¼€å…³ï¼‰
    Returns:
        dict: åˆå¹¶åçš„é…ç½®
    """
    cfg = load_config(config_path, merge_default=True)
    if overrides and isinstance(overrides, dict):
        cfg.update({k: v for k, v in overrides.items() if v is not None})
    # å…œåº•è¾“å‡ºè·¯å¾„
    cfg.setdefault('save_dir', 'runs/train')
    cfg.setdefault('log_dir', 'runs/logs')
    return cfg


def validate_config(config: Dict[str, Any]) -> bool:
    """éªŒè¯é…ç½®å‚æ•°çš„æœ‰æ•ˆæ€§ï¼ˆè·¯å¾„ä¸å…³é”®æ•°å€¼èŒƒå›´ï¼‰ã€‚

    - è·¯å¾„æ£€æŸ¥ä¸å½“å‰ yolo_dataset.build_datasets_and_loaders çº¦å®šä¸€è‡´
    - æ•°å€¼èŒƒå›´ï¼šepochs/lr/batch_size > 0
    """
    print("\néªŒè¯è®­ç»ƒé…ç½®...")

    data_root = config.get('data_root', 'dataset')
    if not os.path.exists(data_root):
        print(f"âœ— æ•°æ®æ ¹ç›®å½•ä¸å­˜åœ¨: {data_root}")
        return False

    train_img_dir = config.get('train_img_dir', 'dataset/images/train')
    val_img_dir = config.get('val_img_dir', 'dataset/images/val')
    train_label_dir = config.get('train_label_dir', 'dataset/labels/train')
    val_label_dir = config.get('val_label_dir', 'dataset/labels/val')

    for pth, desc in [
        (train_img_dir, 'è®­ç»ƒå›¾åƒç›®å½•'),
        (val_img_dir, 'éªŒè¯å›¾åƒç›®å½•'),
        (train_label_dir, 'è®­ç»ƒæ ‡ç­¾ç›®å½•'),
        (val_label_dir, 'éªŒè¯æ ‡ç­¾ç›®å½•'),
    ]:
        if not os.path.exists(pth):
            print(f"âœ— {desc}ä¸å­˜åœ¨: {pth}")
            return False

    if config.get('epochs', 0) <= 0:
        print("âœ— epochså¿…é¡»å¤§äº0")
        return False
    if config.get('lr', 0) <= 0:
        print("âœ— å­¦ä¹ ç‡å¿…é¡»å¤§äº0")
        return False
    if config.get('batch_size', 0) <= 0:
        print("âœ— batch_sizeå¿…é¡»å¤§äº0")
        return False

    print("âœ“ é…ç½®éªŒè¯é€šè¿‡")
    return True


def print_config_summary(config: Dict[str, Any]) -> None:
    """æ‰“å°é…ç½®æ‘˜è¦ã€‚"""
    print("\n" + "="*60)
    print("è®­ç»ƒé…ç½®æ‘˜è¦")
    print("="*60)
    print("ğŸ“Š åŸºæœ¬å‚æ•°:")
    print(f"  - è®­ç»ƒè½®æ•°: {config.get('epochs', 'N/A')}")
    print(f"  - æ‰¹æ¬¡å¤§å°: {config.get('batch_size', 'N/A')}")
    print(f"  - å­¦ä¹ ç‡: {config.get('lr', 'N/A')}")
    print(f"  - å›¾åƒå°ºå¯¸: {config.get('img_size', 'N/A')}")
    print(f"  - æƒé‡è¡°å‡: {config.get('weight_decay', 'N/A')}")
    print("\nğŸ¯ æ¨¡å‹å‚æ•°:")
    print(f"  - ç±»åˆ«æ•°: {config.get('nc', 'N/A')}")
    print(f"  - å…³é”®ç‚¹æ•°: {config.get('nk', 'N/A')}")
    print("\nğŸ“ æ•°æ®è·¯å¾„:")
    print(f"  - æ•°æ®æ ¹ç›®å½•: {config.get('data_root', 'N/A')}")
    print(f"  - è®­ç»ƒå›¾åƒ: {config.get('train_img_dir', 'N/A')}")
    print(f"  - éªŒè¯å›¾åƒ: {config.get('val_img_dir', 'N/A')}")
    print("\nğŸ’¾ è¾“å‡ºè·¯å¾„:")
    print(f"  - æ¨¡å‹ä¿å­˜: {config.get('save_dir', 'N/A')}")
    print(f"  - è®­ç»ƒæ—¥å¿—: {config.get('log_dir', 'N/A')}")
    print("\nğŸ”§ è®­ç»ƒç­–ç•¥:")
    print(f"  - æ—©åœè½®æ•°: {config.get('patience', 'N/A')}")
    print(f"  - éªŒè¯é—´éš”: {config.get('val_interval', 'N/A')}")
    print(f"  - ä¿å­˜é—´éš”: {config.get('save_interval', 'N/A')}")
    print(f"  - æ—©åœ: {config.get('early_stop', 'N/A')}")
    print("\nğŸ¨ æ•°æ®å¢å¼º:")
    # å°è¯•å…¼å®¹ä¸¤å¥—å‘½åï¼ˆconfig.yaml ä¸æ—§ my_train é»˜è®¤ï¼‰
    print(f"  - æ°´å¹³ç¿»è½¬: {config.get('horizontal_flip_prob', config.get('fliplr', 'N/A'))}")
    print(f"  - æ—‹è½¬æ¦‚ç‡: {config.get('rotation_prob', config.get('rotation', 'N/A'))}")
    print(f"  - ç¼©æ”¾æ¦‚ç‡: {config.get('scale_prob', config.get('scale', 'N/A'))}")
    print(f"  - äº®åº¦è°ƒæ•´: {config.get('brightness_range', config.get('brightness', 'N/A'))}")
    print("="*60)


def check_environment(create_dirs: bool = False, save_dir: Optional[str] = None, log_dir: Optional[str] = None) -> bool:
    """æ£€æŸ¥è®­ç»ƒç¯å¢ƒã€‚é»˜è®¤ä»…æŠ¥å‘Š GPU æƒ…å†µï¼›ç›®å½•åˆ›å»ºäº¤ç”± Trainer å…œåº•ã€‚

    Args:
        create_dirs: æ˜¯å¦åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆé€šå¸¸ä¸éœ€è¦ï¼ŒTrainer ä¼šåˆ›å»ºï¼‰
        save_dir: æ¨¡å‹ä¿å­˜ç›®å½•ï¼ˆå½“ create_dirs=True æ—¶ä½¿ç”¨ï¼‰
        log_dir: æ—¥å¿—ç›®å½•ï¼ˆå½“ create_dirs=True æ—¶ä½¿ç”¨ï¼‰
    """
    print("æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")
    if torch.cuda.is_available():
        try:
            device = torch.cuda.get_device_name(0)
            memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"âœ“ GPUå¯ç”¨: {device} ({memory:.1f}GB)")
        except Exception:
            print("âœ“ GPUå¯ç”¨")
    else:
        print("âš  GPUä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")

    if create_dirs and save_dir:
        try:
            os.makedirs(save_dir, exist_ok=True)
            print(f"âœ“ åˆ›å»ºç›®å½•: {save_dir}")
        except Exception:
            pass
    if create_dirs and log_dir:
        try:
            os.makedirs(log_dir, exist_ok=True)
            print(f"âœ“ åˆ›å»ºç›®å½•: {log_dir}")
        except Exception:
            pass

    print("âœ“ ç¯å¢ƒæ£€æŸ¥å®Œæˆ")
    return True


def set_seed(seed: int = 42, deterministic: bool = True, benchmark: bool = False) -> None:
    """è®¾ç½®éšæœºç§å­ä»¥æå‡å¤ç°æ€§ã€‚"""
    try:
        import random as _random
        _random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = bool(deterministic)
        torch.backends.cudnn.benchmark = bool(benchmark)
        print(f"âœ“ å·²è®¾ç½®éšæœºç§å­: {seed}")
    except Exception:
        print("âš  è®¾ç½®éšæœºç§å­å¤±è´¥ï¼ˆå¿½ç•¥ï¼‰")


def create_experiment_name(config: Dict[str, Any], prefix: str = "yolo11_pose") -> str:
    """ç”Ÿæˆå®éªŒåç§°ï¼Œå¦‚: yolo11_pose_e50_b16_lr0.001_YYYYmmdd_HHMMSS"""
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    epochs = config.get('epochs', 'unknown')
    batch_size = config.get('batch_size', 'unknown')
    lr = config.get('lr', 'unknown')
    return f"{prefix}_e{epochs}_b{batch_size}_lr{lr}_{timestamp}"


__all__ = [
    "load_config",
    "DEFAULT_CONFIG",
    "load_training_config",
    "validate_config",
    "print_config_summary",
    "check_environment",
    "set_seed",
    "create_experiment_name",
]
